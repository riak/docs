<p>Although latency is unavoidable in distributed systems like Riak, there
are a number of actions that can be undertaken to reduce latency
to the lowest levels possible within a cluster. In this guide, we’ll
list potential sources of high latency and what you can do about it.</p>

<h2 id="large-objects">Large Objects</h2>

<p>Riak always performs best with smaller objects. Large objects, which can
be mistakenly inserted into Riak by your application or caused by
siblings (see below), can often increase latency.</p>

<p>We recommend keeping all objects stored in Riak smaller than 1-2 MB,
preferably below 100 KB. Large objects lead to increased I/O activity
and can put strain on memory resources. In some cases, just a few large
objects can impact latency in a cluster, even for requests that are
unrelated to those objects.</p>

<p>If your use case requires large objects, we recommend checking out
<a href="/riak/cs/latest/">Riak CS</a>, which is intended as a storage system for large objects.</p>

<h3 id="mitigation">Mitigation</h3>

<p>The best way to find out if large objects are impacting latency is to
monitor each node’s object size stats. If you run <a href="../../admin/riak-admin/#status"><code class="language-plaintext highlighter-rouge">riak-admin status</code></a> or make an HTTP <code class="language-plaintext highlighter-rouge">GET</code> request
to Riak’s <code class="language-plaintext highlighter-rouge">/stats</code> endpoint, you will see the results for the following
metrics related to object size, all of which are calculated only for
<code class="language-plaintext highlighter-rouge">GET</code> operations (i.e. reads):</p>

<table>
  <thead>
    <tr>
      <th style="text-align: left">Metric</th>
      <th style="text-align: left">Explanation</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: left"><code class="language-plaintext highlighter-rouge">fsm_node_get_objsize_mean</code></td>
      <td style="text-align: left">The mean object size encountered by this node in the last minute</td>
    </tr>
    <tr>
      <td style="text-align: left"><code class="language-plaintext highlighter-rouge">fsm_node_get_objsize_median</code></td>
      <td style="text-align: left">The median object size encountered by this node in the last minute</td>
    </tr>
    <tr>
      <td style="text-align: left"><code class="language-plaintext highlighter-rouge">fsm_node_get_objsize_95</code></td>
      <td style="text-align: left">The 95th-percentile object size encountered by this node in the last minute</td>
    </tr>
    <tr>
      <td style="text-align: left"><code class="language-plaintext highlighter-rouge">fsm_node_get_objsize_99</code></td>
      <td style="text-align: left">The 99th-percentile object size encountered by this node in the last minute</td>
    </tr>
    <tr>
      <td style="text-align: left"><code class="language-plaintext highlighter-rouge">fsm_node_get_objsize_100</code></td>
      <td style="text-align: left">The 100th-percentile object size encountered by this node in the last minute</td>
    </tr>
  </tbody>
</table>

<p>The <code class="language-plaintext highlighter-rouge">mean</code> and <code class="language-plaintext highlighter-rouge">median</code> measurements may not be good indicators,
especially if you’re storing billions of keys. Instead, you should be on
the lookout for trends in the <code class="language-plaintext highlighter-rouge">95</code>, <code class="language-plaintext highlighter-rouge">99</code>, and <code class="language-plaintext highlighter-rouge">100</code> measures:</p>

<ul>
  <li>Is there an upward trend?</li>
  <li>Do the metrics indicate that there are outliers?</li>
  <li>Do these trends coincide with increased latency?</li>
</ul>

<p>If you suspect that large object size is impacting latency, try making
the following changes to each node’s <a href="../../../configuring/reference">configuration</a>:</p>

<ul>
  <li>If you are using the newer, <code class="language-plaintext highlighter-rouge">riak.conf</code>-based configuration system,
the commented-out value for <code class="language-plaintext highlighter-rouge">erlang.distribution_buffer_size</code> is <code class="language-plaintext highlighter-rouge">32MB</code>.
Uncomment this setting and re-start your node.</li>
  <li>If you are using the older, <code class="language-plaintext highlighter-rouge">app.config</code>/<code class="language-plaintext highlighter-rouge">vm.args</code>-based configuration
system, try increasing the <code class="language-plaintext highlighter-rouge">+zddbl</code> setting in <code class="language-plaintext highlighter-rouge">vm.args</code> to <code class="language-plaintext highlighter-rouge">32768</code> or
higher (measured in kilobytes). This increases the size of the
distributed Erlang buffer from its default of 1024 KB. Re-start your
node when configuration changes have been made.</li>
</ul>

<p>Large objects can also impact latency even if they’re only present on
some nodes. If increased latency occurs only on N nodes, where N is your
<a href="../../../developing/app-guide/replication-properties/#n-value-and-replication">replication factor</a>, also known as <code class="language-plaintext highlighter-rouge">n_val</code>, this could indicate that a single large object and its replicas are slowing down <em>all</em> requests on those nodes.</p>

<p>If large objects are suspected, you should also audit the behavior of
siblings in your cluster, as explained in the <a href="#siblings">next section</a>.</p>

<h2 id="siblings">Siblings</h2>

<p>In Riak, object conflicts are handled by keeping multiple versions of
the object in the cluster either until a client takes action to resolve
the conflict or until <a href="../../../learn/glossary/#active-anti-entropy">active anti-entropy</a> resolves the conflict without client intervention. While sibling production is normal, <a href="../../../learn/concepts/causal-context/#sibling-explosion">sibling explosion</a> is a problem that can come about if many siblings of an object are produced. The negative effects are the same as those associated with <a href="#large-objects">large objects</a>.</p>

<h3 id="mitigation-1">Mitigation</h3>

<p>The best way to monitor siblings is through the same <a href="../../admin/riak-admin/#status"><code class="language-plaintext highlighter-rouge">riak-admin status</code></a> interface used to monitor
object size (or via an HTTP <code class="language-plaintext highlighter-rouge">GET</code> request to <code class="language-plaintext highlighter-rouge">/stats</code>). In the output of
<code class="language-plaintext highlighter-rouge">riak-admin status</code> in each node, you’ll see the following
sibling-related statistics:</p>

<table>
  <thead>
    <tr>
      <th style="text-align: left">Metric</th>
      <th style="text-align: left">Explanation</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: left"><code class="language-plaintext highlighter-rouge">node_get_fsm_siblings_mean</code></td>
      <td style="text-align: left">The mean number of siblings encountered during all GET operations by this node within the last minute</td>
    </tr>
    <tr>
      <td style="text-align: left"><code class="language-plaintext highlighter-rouge">node_get_fsm_siblings_median</code></td>
      <td style="text-align: left">The median number of siblings encountered during all GET operations by this node within the last minute</td>
    </tr>
    <tr>
      <td style="text-align: left"><code class="language-plaintext highlighter-rouge">node_get_fsm_siblings_95</code></td>
      <td style="text-align: left">The 95th percentile of the number of siblings encountered during all GET operations by this node within the last minute</td>
    </tr>
    <tr>
      <td style="text-align: left"><code class="language-plaintext highlighter-rouge">node_get_fsm_siblings_99</code></td>
      <td style="text-align: left">The 99th percentile of the number of siblings encountered during all GET operations by this node within the last minute</td>
    </tr>
    <tr>
      <td style="text-align: left"><code class="language-plaintext highlighter-rouge">node_get_fsm_siblings_100</code></td>
      <td style="text-align: left">The 100th percentile of the number of siblings encountered during all GET operations by this node within the last minute</td>
    </tr>
  </tbody>
</table>

<p>Is there an upward trend in these statistics over time? Are there any
large outliers? Do these trends correspond to your observed latency
spikes?</p>

<p>If you believe that sibling creation problems could be responsible for
latency issues in your cluster, you can start by checking the following:</p>

<ul>
  <li>If <code class="language-plaintext highlighter-rouge">allow_mult</code> is set to <code class="language-plaintext highlighter-rouge">true</code> for some or all of your buckets, be
sure that your application is correctly resolving siblings. Be sure to
read our documentation on <a href="../../../developing/usage/conflict-resolution">conflict resolution</a> for a fuller picture of how this can be done. <strong>Note</strong>: In Riak versions 2.0 and later, <code class="language-plaintext highlighter-rouge">allow_mult</code> is set to <code class="language-plaintext highlighter-rouge">true</code> by default for all bucket types that you create and activate.
If you wish to set <code class="language-plaintext highlighter-rouge">allow_mult</code> to <code class="language-plaintext highlighter-rouge">false</code> on a bucket type, you will have to do so explicitly.</li>
  <li>Application errors are a common source of problems with
siblings. Updating the same key over and over without passing a
<a href="../../../learn/concepts/causal-context">causal context</a> to Riak can cause sibling explosion. If this seems to be the issue, modify your application’s <a href="../../../developing/usage/conflict-resolution">conflict resolution</a>
strategy. Another possibility worth exploring is using <a href="../../../learn/concepts/causal-context/#dotted-version-vectors">dotted version vectors</a> (DVVs) in place of traditional vector clocks. DVVs can be enabled <a href="../../../developing/usage/bucket-types">using bucket types</a> by setting the <code class="language-plaintext highlighter-rouge">dvv_enabled</code> parameter to <code class="language-plaintext highlighter-rouge">true</code> for buckets that seem to be experiencing sibling explosion.</li>
</ul>

<h2 id="compaction-and-merging">Compaction and Merging</h2>

<p>The <a href="../../../setup/planning/backend/bitcask">Bitcask</a> and <a href="../../../setup/planning/backend/leveldb">LevelDB</a> storage backends occasionally go through
heavily I/O-intensive compaction phases during which they remove deleted
data and reorganize data files on disk. During these phases, affected
nodes may be slower to respond to requests than other nodes. If your
cluster is using one or both of these backends, there are steps that can
be taken to monitor and address latency issues.</p>

<h3 id="mitigation-2">Mitigation</h3>

<p>To determine whether compaction and merging cycles align with increased
latency, keep an eye on on your <code class="language-plaintext highlighter-rouge">console.log</code> files (and LevelDB <code class="language-plaintext highlighter-rouge">LOG</code>
files if you’re using LevelDB). Do Bitcask merging and/or LevelDB
compaction events overlap with increased latencies?</p>

<p>If so, our first recommendation is to examine your <a href="../../../developing/app-guide/replication-properties/">replication properties</a> to make sure that neither R nor W are set to N, i.e. that you’re not requiring that reads or writes go to all nodes in the cluster. The problem with setting <code class="language-plaintext highlighter-rouge">R=N</code> or <code class="language-plaintext highlighter-rouge">W=N</code> is that any request will only respond as quickly as the slowest node amongst the N nodes involved in the request.</p>

<p>Beyond checking for <code class="language-plaintext highlighter-rouge">R=N</code> or <code class="language-plaintext highlighter-rouge">W=N</code> for requests, the recommended
mitigation strategy depends on the backend:</p>

<h4 id="bitcask">Bitcask</h4>

<p>With Bitcask, it’s recommended that you:</p>

<ul>
  <li>Limit merging to off-peak hours to decrease the effect of merging
cycles on node traffic</li>
  <li>Stagger merge windows between nodes so that no more than one node is
undergoing a merge phase at any given time</li>
</ul>

<p>Instructions on how to accomplish both can be found in our guide to
<a href="../../../setup/planning/backend/bitcask/#tuning-bitcask">tuning Bitcask</a>.</p>

<p>It’s also important that you adjust your maximum file size and merge
threshold settings appropriately. This setting is labeled
<code class="language-plaintext highlighter-rouge">bitcask.max_file_size</code> in the newer, <code class="language-plaintext highlighter-rouge">riak.conf</code>-based <a href="../../../configuring/reference">configuration files</a> and <code class="language-plaintext highlighter-rouge">max_file_size</code> in the older, <code class="language-plaintext highlighter-rouge">app.config</code>-based system.</p>

<p>Setting the maximum file size lower will cause Bitcask to merge more
often (with less I/O churn), while setting it higher will induce less
frequent merges with more I/O churn. To find settings that are ideal for
your use case, we recommend checking out our guide to <a href="../../../setup/planning/backend/bitcask/#configuring-bitcask">configuring Bitcask</a>.</p>

<h4 id="leveldb">LevelDB</h4>

<p>The more files you keep in memory, the faster LevelDB will perform in
general. To make sure that you are using your system resources
appropriately with LevelDB, check out our guide to <a href="../../../setup/planning/backend/leveldb/#parameter-planning">LevelDB parameter planning</a>.</p>

<h2 id="os-tuning">OS Tuning</h2>

<p>While a number of latency-related problems can manifest themselves in
development and testing environments, some performance limits only
become clear in production environments.</p>

<h3 id="mitigation-3">Mitigation</h3>

<p>If you suspect that OS-level issues might be impacting latency, it might
be worthwhile to revisit your OS-specific configurations. The following
guides may be of help:</p>

<ul>
  <li><a href="../open-files-limit">Open files limit</a></li>
  <li>General <a href="../">System performance tuning</a></li>
  <li><a href="../amazon-web-services">AWS performance tuning</a> if you’re running Riak on <a href="http://aws.amazon.com/">Amazon Web Services</a></li>
</ul>

<h2 id="io-and-network-bottlenecks">I/O and Network Bottlenecks</h2>

<p>Riak is a heavily I/O- and network resource-intensive system.
Bottlenecks on either front can lead to undue latency in your cluster.
We recommend an active monitoring strategy to detect problems
immediately when they arise.</p>

<h3 id="mitigation-4">Mitigation</h3>

<p>To diagnose potential I/O bottlenecks, there are a number of Linux tools
at your disposal, including
<a href="http://www.linuxquestions.org/questions/linux-newbie-8/what-is-iowait-415961/">iowait</a>
and <a href="http://en.wikipedia.org/wiki/Netstat">netstat</a>.</p>

<p>To diagnose potential overloads, Riak versions 1.3.2 and later come
equipped with an overload protection feature designed to prevent
cascading failures in overly busy nodes. This feature limits the number
of GET and PUT finite state machines (FSMs) that can exist
simultaneously on a single Riak node. Increased latency can result if a
node is frequently running up against these maximums.</p>

<ul>
  <li>Monitor <code class="language-plaintext highlighter-rouge">node_get_fsm_active</code> and <code class="language-plaintext highlighter-rouge">node_get_fsm_active_60s</code> to get an
idea of how many operations your nodes are coordinating. If you see
non-zero values in <code class="language-plaintext highlighter-rouge">node_get_fsm_rejected</code> or
<code class="language-plaintext highlighter-rouge">node_get_fsm_rejected_60s</code>, that means that some of your requests are
being discarded due to overload protection.</li>
  <li>The FSM limits can be increased, but disabling overload protection
entirely is not recommended. More details on these settings are
available in the <a href="https://github.com/basho/riak/blob/1.3/RELEASE-NOTES.md">release
notes</a> for
Riak version 1.3.</li>
</ul>

<h2 id="object-settings">Object Settings</h2>

<p>In versions 2.0 and later, Riak enables you to configure a variety of
settings regarding Riak objects, including allowable object sizes, how
many <a href="../../../learn/concepts/causal-context/#siblings">siblings</a> to allow, and so on. If you suspect that undue latency in your cluster stems from object size or related factors, you may consider adjusting these settings.</p>

<p>A concise listing of object-related settings can be found in the <a href="../../../configuring/reference/#object-settings">Riak configuration</a> documentation. The sections below explain these settings in detail.</p>

<blockquote>
  <p><strong>Note on configuration files in 2.0</strong></p>

  <p>The object settings listed below are only available using the new system
for <a href="../../../configuring/reference/">configuration files</a> in Riak 2.0. If you are using the older, <code class="language-plaintext highlighter-rouge">app.config</code>-based system, you will not have access to
these settings.</p>
</blockquote>

<h3 id="object-size">Object Size</h3>

<p>As stated above, we recommend <em>always</em> keeping objects below 1-2 MB
and preferably below 100 KB if possible. If you want to ensure that
objects above a certain size do not get stored in Riak, you can do so by
setting the <code class="language-plaintext highlighter-rouge">object.size.maximum</code> parameter lower than the default of
<code class="language-plaintext highlighter-rouge">50MB</code>, which is far above the ideal object size. If you set this
parameter to, say, <code class="language-plaintext highlighter-rouge">1MB</code> and attempt to store a 2 MB object, the write
will fail and an error message will be returned to the client.</p>

<p>You can also set an object size threshold past which a write will
succeed but will register a warning in the logs, you can adjust the
<code class="language-plaintext highlighter-rouge">object.size.warning_threshold</code> parameter. The default is <code class="language-plaintext highlighter-rouge">5MB</code>.</p>

<h3 id="sibling-explosion-management">Sibling Explosion Management</h3>

<p>In order to prevent or cut down on <a href="../../../learn/concepts/causal-context/#sibling explosion">sibling explosion</a>, you can either prevent Riak from storing
additional siblings when a specified sibling count is reached or set a
warning threshold past which Riak logs an error (or both). This can be
done using the <code class="language-plaintext highlighter-rouge">object.siblings.maximum</code> and
<code class="language-plaintext highlighter-rouge">object.siblings.warning_threshold</code> settings. The default maximum is 100
and the default warning threshold is 25.</p>

<h3 id="object-storage-format">Object Storage Format</h3>

<p>There are currently two possible binary representations for objects
stored in Riak:</p>

<ul>
  <li>Erlang’s native <code class="language-plaintext highlighter-rouge">term_to_binary</code> format, which tends to have a higher
space overhead</li>
  <li>A newer, Riak-specific format developed for more compact storage of
smaller values</li>
</ul>

<p>You can set the object storage format using the <code class="language-plaintext highlighter-rouge">object.format</code>
parameter: <code class="language-plaintext highlighter-rouge">0</code> selects Erlang’s <code class="language-plaintext highlighter-rouge">term_to_binary</code> format while <code class="language-plaintext highlighter-rouge">1</code> (the
default) selects the Riak-specific format.</p>
