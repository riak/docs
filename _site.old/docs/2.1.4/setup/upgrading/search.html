<p>If you’re using Search in a version of Riak prior to 2.0 (1.3.0 to
1.4.x), you should follow these steps to migrate your search indexes
from the legacy <code class="language-plaintext highlighter-rouge">merge_index</code> to the new Solr-backed (<a href="../../../using/reference/search">Yokozuna</a> indexes. The legacy version of Riak Search is now deprecated
and does not support most new 2.0 features, i.e. no <a href="../../../developing/data-types">Riak Data Types</a>, <a href="../../../using/reference/bucket-types">bucket types</a>, <a href="../../../using/reference/strong-consistency">strong consistency</a>, or <a href="../../../using/security/">security</a>), so we highly recommend that you migrate.</p>

<p>And please note that the legacy <code class="language-plaintext highlighter-rouge">merge_index</code>-based search (aka legacy
Search) will be removed in a future release of Riak.</p>

<h2 id="overview-of-an-upgrade">Overview of an Upgrade</h2>

<p>The migration steps explained here are as automated as they can
reasonably be, but they do include some manual steps for safety. They
are meant to be run on a live cluster, so there’s no need to take all of
your nodes down. Like all migration activities, you should undertake
these steps at a time when your cluster is relatively light on traffic,
i.e. <em>not</em> the week before Christmas.</p>

<p>The main goal of a live migration is to stand up indexes in the new Riak
Search that parallel the existing ones in legacy. New writes add entries
to both indexes while AAE adds entries in the new indexes for existing
data.</p>

<p>Parallel indexes mean more disk usage. How much more will depend on the
schema but tests have shown Solr to generally use less disk space. A
prudent plan will expect new Search to use as much disk as legacy. You
can also expect more CPU usage as analysis will temporarily be performed
by both systems. Finally, Solr runs on a JVM process requiring its own
RAM. A good start is 2 GB but more will be required for heavier
workloads. On the contrary, do not make too large a heap as it could
cause lengthy garbage collection pauses.</p>

<p>As the new search indexes catch up with the old, incoming queries will
still be serviced by legacy Search. Once you have determined that the
new indexes are consistent with KV, you can perform a live switch to the
new system and turn off legacy Search. Finally, you can remove the old
merge index directories to reclaim disk space.</p>

<blockquote>
  <p><strong>Downgrading and Merge Index</strong></p>

  <p>It may be tempting to keep the merge index files in case of a downgrade.
We don’t recommend doing that if writes are being made to these buckets
during upgrade.  Once <code class="language-plaintext highlighter-rouge">search: false</code> is set on a bucket, all new KV
data written will have missing indexes in the merge index and
overwritten data will have inconsistent indexes. At this point, a
downgrade requires a full re-index of the data as legacy Search has no
mechanism to cope with inconsistency (such as <a href="../../../learn/glossary/#active-anti-entropy-aae">active anti-entropy</a> in the new Search).</p>
</blockquote>

<blockquote>
  <p><strong>Active Anti-Entropy (AAE) Required</strong></p>

  <p>Migration requires that Riak’s AAE subsystem be enabled. It’s
responsible for finding all the missing index entries for existing data
and adding them. Technically speaking, the migration can be performed
without AAE, but it will require a key listing or <a href="../../../developing/usage/mapreduce">MapReduce</a> job that re-indexes every object. This method will use more CPU, network, and especially disk space from merge index as its GC
algorithm is bad at getting rid of large index files.</p>
</blockquote>

<h2 id="steps-to-upgrading">Steps to Upgrading</h2>

<ol>
  <li>
    <p>First, you’ll perform a normal <a href="../cluster">rolling upgrade</a>.
As you upgrade, enable <code class="language-plaintext highlighter-rouge">yokozuna</code> (the new Riak Search library) on
each node. If you’re still using <code class="language-plaintext highlighter-rouge">app.config</code> it’s called <code class="language-plaintext highlighter-rouge">yokozuna</code>.
If you’ve chosen to upgrade to the new <code class="language-plaintext highlighter-rouge">riak.conf</code> config option, it’s
called <code class="language-plaintext highlighter-rouge">search</code>.</p>

    <pre><code class="language-riakconf">search = on
</code></pre>
    <pre><code class="language-appconfig">{yokozuna, [
            %% Other configs
            {enabled, true},
            %% Other configs
           ]}
</code></pre>

    <div class="note">
<div class="title">Upgrade First</div>
Don't proceed until all nodes have been upgraded to the newest
version. This way all nodes have new Search capabilities before
running the next steps which require them.
</div>
  </li>
  <li>
    <p>For every schema in legacy Search, you must create a comparable
schema in new Search. If you want to use the default schema named
<a href="../../../developing/usage/search-schemas">_yz_default</a>, you can skip this step, but we highly recommend you create your own custom schema.</p>

    <p>To create a schema, you can follow the Solr <a href="../../../developing/usage/search-schemas">search schema</a>
 instructions to learn how to define your xml file. Once you’ve created
 the file, you can upload it to the cluster.</p>

    <pre><code class="language-curl"> curl -XPUT http://localhost:8098/search/schema/my_schema \
   -H 'Content-Type: application/xml' \
   --data-binary @my_schema.xml
</code></pre>
  </li>
  <li>
    <p>For every index in legacy Search, you must create a comparable index
in new Search, setting the appropriate schema that you created in the
previous step. This index can have the same name as your legacy Search
index. You can find more details about index creation under <a href="../../../developing/usage/search/#setup">Using Search</a>.</p>

    <pre><code class="language-curl"> curl -XPUT http://localhost:8098/search/index/my_index \
   -H 'Content-Type: application/json' \
   -d '{"schema":"my_schema"}'
</code></pre>
  </li>
  <li>
    <p>For each bucket which is indexed by legacy Search, you must add the
<code class="language-plaintext highlighter-rouge">search_index</code> bucket property to point to the new Search index. This
new index is what we are attempting to migrate all of our index data to.
You can find more details about this step under <a href="../../../developing/usage/search/#setup">Using Search</a>.</p>

    <pre><code class="language-curl"> curl -XPUT http://localhost:8098/buckets/my_bucket/props \
   -H 'Content-Type: application/json' \
   -d '{"props":{"search_index":"my_index"}}'
</code></pre>

    <p>Once a bucket is associated with the new Search, all objects that are
 written or modified in Riak will be indexed by <strong>both</strong> legacy and new
 Search. However, the HTTP and client query interfaces will still
 continue to use the legacy Search.</p>
  </li>
  <li>
    <p>The new Search <a href="../../../learn/glossary/#active-anti-entropy-aae">AAE</a> hash
trees must be manually cleared so that AAE will notice the missing
indexes.</p>

    <p>Attach to one of the Riak nodes by calling <code class="language-plaintext highlighter-rouge">riak attach-direct</code>. Paste
 the following code into the shell. It clears the Search hash trees for
 each node in the cluster.</p>

    <div class="language-erlang highlighter-rouge"><div class="highlight"><pre class="highlight"><code> <span class="nn">riak_core_util</span><span class="p">:</span><span class="nf">rpc_every_member_ann</span><span class="p">(</span><span class="n">yz_entropy_mgr</span><span class="p">,</span> <span class="n">clear_trees</span><span class="p">,</span> <span class="p">[],</span> <span class="n">infinity</span><span class="p">).</span>
</code></pre></div>    </div>

    <p>Press <code class="language-plaintext highlighter-rouge">Ctrl-D</code> to exit from the attached shell.</p>

    <p>In the background AAE will rebuild the hash trees and exchange them
 with KV. These exchanges will notice objects are missing and index
 them in new Search.</p>

    <p><!-- no re-index command currently exists --></p>
  </li>
  <li>
    <p>Monitor the AAE status of every node until a full round of exchanges
have occurred on every node.</p>

    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code> riak-admin search aae-status
</code></pre></div>    </div>

    <p>First, you must wait until all trees are rebuilt. This may take a
 while as each node is configured, by default, to build a maximum of
 one tree per hour. You can determine when a tree is build by looking
 at the <code class="language-plaintext highlighter-rouge">Entropy Trees</code> section. When a tree is not built it will show
 <code class="language-plaintext highlighter-rouge">--</code> under the <code class="language-plaintext highlighter-rouge">Built (ago)</code> column. Otherwise, it will list how long
 ago the tree was built in a human friendly format. Here is an example
 of trees that are not built:</p>

    <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code> ================================ Entropy Trees ================================
 Index                                              Built (ago)
 -------------------------------------------------------------------------------
 ...
 296867520082839655260123481645494988367611297792   --
 319703483166135013357056057156686910549735243776   --
 ...
</code></pre></div>    </div>

    <p>Here is an example of built trees:</p>

    <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code> ================================ Entropy Trees ================================
 Index                                              Built (ago)
   -------------------------------------------------------------------------------
 ...
 296867520082839655260123481645494988367611297792   12.3 hr
 319703483166135013357056057156686910549735243776   5.3 hr
 ...
</code></pre></div>    </div>

    <p>After all the trees are built you then have to wait for a full
 exchange round to occur for every partition on every node.  That is,
 the full exchange round must be <strong>NEWER</strong> than the time the tree was
 built.  That way you know the exchange was based on the latest tree.
 The exchange information is found under the <code class="language-plaintext highlighter-rouge">Exchanges</code> section.
 Under that section there are two columns: <code class="language-plaintext highlighter-rouge">Last (ago)</code> and <code class="language-plaintext highlighter-rouge">All
 (ago)</code>.  In this was you want to wait until the <code class="language-plaintext highlighter-rouge">All (ago)</code> section is
 newer than the value of <code class="language-plaintext highlighter-rouge">Built (ago)</code> in the <code class="language-plaintext highlighter-rouge">Entropy Trees</code> section.
 For example, given the entropy tree output above this output would
 indicate both partitions have had a full exchange round since the
 latest tree was built:</p>

    <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code> ================================== Exchanges ==================================
 Index                                              Last (ago)    All (ago)
 -------------------------------------------------------------------------------
 ...
 296867520082839655260123481645494988367611297792   12.1 hr       12.1 hr
 319703483166135013357056057156686910549735243776   5.1 hr        5.2 hr
 ...
</code></pre></div>    </div>

    <p>Notice that <code class="language-plaintext highlighter-rouge">12.1 hr</code> is newer than <code class="language-plaintext highlighter-rouge">12.3 hr</code> and <code class="language-plaintext highlighter-rouge">5.2 hr</code> newer than
 <code class="language-plaintext highlighter-rouge">5.3 hr</code>. Once the exchange is newer for every partition on every
 node you know that AAE has brought all new indexes up to date.</p>
  </li>
  <li>
    <p>Next, call the following command that will give HTTP and PB query
control to the new Riak Search.</p>

    <pre><code class="language-curl"> riak-admin search switch-to-new-search
</code></pre>

    <div class="note">
 <div class="title">Check Results Before Switching (Optional)</div>
 Up until this point all incoming queries are serviced by the legacy
 Search system.  After the `switch-to-new-search` is run all queries
 will be handled by new Search.  If you first want to verify the
 results of new Search before switching then you can use its dedicated
 HTTP resource at `/search/query/<index>?q=...`.
 &lt;/div&gt;

</index></div>
  </li>
  <li>
    <p>Set the <code class="language-plaintext highlighter-rouge">search</code> bucket property to <code class="language-plaintext highlighter-rouge">false</code> for all legacy indexed
buckets. This deactivates legacy Search.</p>

    <pre><code class="language-curl"> curl -XPUT "http://localhost:8098/buckets/my_bucket/props" \
   -H 'Content-Type: application/json' \
   -d '{"props":{"search": false}}'
</code></pre>
  </li>
  <li>
    <p>Disable the Riak Search process on each node by setting <code class="language-plaintext highlighter-rouge">riak_search</code>
<code class="language-plaintext highlighter-rouge">enabled</code> to <code class="language-plaintext highlighter-rouge">false</code>.</p>

    <pre><code class="language-appconfig"> {riak_search, [
                %% Other configs
                {enabled, false},
                %% Other configs
               ]},
</code></pre>
  </li>
  <li>
    <p>Perform a rolling restart. This is needed both to stop legacy
Search as well as properly remove the legacy Search commit hooks. A bug
in the 1.4.x series allowed bucket properties to leak into what Riak
developers call the “raw ring”. In the case of legacy Search it causes
the commit hooks to persist even when legacy Search is disable and the
search property is set to false.</p>

    <p>New Search has code to expunge the legacy hooks from the raw ring but
it only occurs during start-up and requires that legacy Search be
disabled in the configuration.  Thus, the easiest way to fix things is
to disable legacy Search (in step 9) and then perform a rolling
restart of the cluster.</p>
  </li>
  <li>
    <p>Finally, delete the merge index directories to reclaim disk space.</p>
  </li>
</ol>

<p>For any questions reach out to the <a href="/community">Riak community</a>. Preferably, ask your questions up front rather than during the middle of a migration.</p>
